redesign of code structure count : 5 
I didn't rewrite the data analysis mind you. However it WAS done so it DOES count

the done section writes every step I did ; some of them are obsolete (for example I changed 
implem of graphs multiple times) but it's a good way to track my progress

done : 

    - graphs are kinda implemented
        - I can add stuf to them 
        - I can print them (I can't load them from a file yet though)

        - I can also load them let's go 
    
    - script can load a city into a networkx graph thingy (easy part) 

    - walker structure pretty much done 

    - apparently I wrote a tactics structure I didn't even remember it 

    - rewrote the graph implem in the GraphTable structure 

    - wrote the table manip fn ; haven't tested them yet

    - graph table fully implmented 

    - deleted deprecated stuff

    - implemented some of the movement ; tested it 

    - finished the python script ( written the discretisation function and functions to read / 
      write custom CSVs ) nb : the loadCSV function doesn't care for flux atm but it will at some
      point 

    - test the new wte structure 
    - test the updated graph_table functions 

    - movement mostly done ; problem with the update of flux for some 
      reason (not anymore)

    -fixed the flux

    - do some proper testing of simulations (kinda)

    - write the tactics stuff (tested ) (now it is)

    - write propper error reporting 

    - put error reporting at the right place 

    - re implement tactics

    - test tactics (kind of done )

    - write the actual main n maybe do a script to call stuff in bash or smtg 
      ( finished ; tested )
    
    - find out how to parse tactics  (tested yet )

    - removed some of the unnecessary elements from the structure ; 
      watch out for potential bugs IG

    - finish docu (docu of usage is still pending bc main isn't done yet )

    - write a wrapper around trace dump

    - tested main 

    - test tactics parsing

    - write the different rules 

    - format output 

    - separate mutable / immutable fields of walkers (necessary to create relevant trace)
      I actually just replaced the posref inside the walker to an uint32 representing 
      the index so it should work now 
    
    - remove more elements from structures to gain space (I might be able to remove more 
      but I'm not sure what I could do tbh)
    
    - write the whole load trace python script

    - implemented the coefficient based attraction rule

    - make the movement choice a meta tactic 

    - make sure that the program behaves well when not given optionnal args

    - scale walker num like opt args

    - fix the args handling (I think)

    - heavy perftest : tested  time complexity of different rules ; 
      results were predictible ; 
      from slowest to fastest : 

      attco 
      align 
      attra 
      rand
      sleep 

    - tested multi threading ; thread management is slower than running the actual 
      simulation on small scale (lol)
      might retest w a bigger graph I dunno 
    
    - found out something really weird : the space complexity DID NOT 
      affect the number of nodes where I get out of the cache so I'm not sure what 
      causes me to break in perftest. I'm really confused

    - perftest another 20000walker * 1000 it simul cuz the last result was fucked up 
      done; results are what were expected but kinda disapointing
    
    - wrote + tested most of the dt analysis functions ; haven't tested 
      the nb nodes visited by walkers yet 
    
    - wrote python script to start 1 simulation and generate it's trace 

    - change the way dumping works program should dump w smtg like 
      "-d tname" and then create tname_flux tname_curnum , ...
    
    -  fix the number of threads used for the program (not tested )

    - figure out proper way to parse walking_on_graphs rules 
      they can be given as a single beeg string to bash and it will then 
      be read correctly by the C program (cool)
    
    - implement rule parsing 

    - finish the shell / python wrapper for the program 
      wire up the different sections of the prgm smtg like : 
      python retriever -> C simulation -> python trace loader -> python dt analysis 
                        (possibility to run the simulation a bunch of times to get avg of simul)
    
    - start simulations in batch on multiple CPUs (the idea is that 1 simulation is too fast to 
      benefit of multithread so just start a bunch of them on a bunch of threads)
    
    - implemented / tested a script to start simulations w random parameters to generate a LOT 
      of data will run it during the week end
    
    - implement the nb_nodes_visited / walkers stuff (ty pacidus)

    - optimize the python stuff  ( call for help)

    - dt analysis was heavily optimized by https://github.com/Pacidus

    - data analysis is : done (yes. yes. yes.)


pending : 

    Data analysis : 
      
      - the flux thing I forgot what it was supposed to be exactly 
 
    C Optimization : 

      - evaluate meta fns with variant of other fns and stuff to try and gain performance

      - use __builtin_prefetch

      - do the malloc wrapper arena/mempool thingy  (YES I WANNA COME ON)

    Misc:    

      - possibility to start simulation w an array of walkers 

      - create a small db by randomising simul and write a python script to do queries on it

      - remove curse words from commentaries and documentation